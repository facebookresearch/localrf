_parent_: options/base.yaml

arch:                                                       # architectural optionss
    layers_feat: [null,256,256,256,256,256,256,256,256]     # hidden layers for feature/density MLP]
    layers_rgb: [null,128,3]                                # hidden layers for color MLP]
    skip: [4]                                               # skip connections
    posenc:                                                 # positional encoding:
        L_3D: 10                                            # number of bases (3D point)
        L_view: 4                                           # number of bases (viewpoint)
    density_activ: softplus                                 # activation function for output volume density
    tf_init: true                                           # initialize network weights in TensorFlow style

nerf:                                                       # NeRF-specific options
    view_dep: true                                          # condition MLP on viewpoint
    depth:                                                  # depth-related options
        param: inverse                                      # depth parametrization (for sampling along the ray)
        range: [1,0]                                        # near/far bounds for depth sampling
    sample_intvs: 128                                       # number of samples
    sample_stratified: true                                 # stratified sampling
    fine_sampling: false                                    # hierarchical sampling with another NeRF
    sample_intvs_fine:                                      # number of samples for the fine NeRF
    rand_rays: 2048                                         # number of random rays for each step
    density_noise_reg:                                      # Gaussian noise on density output as regularization
    setbg_opaque:                                           # fill transparent rendering with known background color (Blender only)

data:                                                       # data options
    dataset: llff                                           # dataset name
    scene: fern                                             # scene name
    image_size: [480,640]                                   # input image sizes [height,width]
    num_workers: 4                                          # number of parallel workers for data loading
    preload: true                                           # preload the entire dataset into the memory
    val_ratio: 0.1                                          # ratio of sequence split for validation

camera:                                                     # camera options
    model: perspective                                      # type of camera model
    ndc: false                                              # reparametrize as normalized device coordinates (NDC)

loss_weight:                                                # loss weights (in log scale)
    render: 0                                               # RGB rendering loss
    render_fine:                                            # RGB rendering loss (for fine NeRF)

optim:                                                      # optimization options
    lr: 1.e-3                                               # learning rate (main)
    lr_end: 1.e-4                                           # terminal learning rate (only used with sched.type=ExponentialLR)
    sched:                                                  # learning rate scheduling options
        type: ExponentialLR                                 # scheduler (see PyTorch doc)
        gamma:                                              # decay rate (can be empty if lr_end were specified)

batch_size:                                                 # batch size (not used for NeRF/BARF)
max_epoch:                                                  # train to maximum number of epochs (not used for NeRF/BARF)
max_iter: 200000                                            # train to maximum number of iterations

freq:                                                       # periodic actions during training
    scalar: 200                                             # log losses and scalar states (every N iterations)
    vis: 1000                                               # visualize results (every N iterations)
    val: 25000                                              # validate on val set (every N iterations)
    ckpt: 5000                                              # save checkpoint (every N iterations)

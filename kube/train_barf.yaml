apiVersion: batch/v1
kind: Job
metadata:
  name: 'uberlapse-train-barf'
spec:
  ttlSecondsAfterFinished: 60
  completions: 7
  parallelism: 7
  completionMode: Indexed
  template:
    spec:
      restartPolicy: Never
      containers:
      - name: uberlapse
        resources:
          limits:
            cpu: 6
            memory: 40Gi
            nvidia.com/gpu: 1
        image: "dtr.thefacebook.com/ameuleman/uberlapse:latest"
        volumeMounts:
        - name: uberlapse
          mountPath: /mnt/uberlapse
        command:
          - "bash"
          - "-c"
          - |
            cd /mnt/uberlapse/ameuleman
            SCENES=(ours/uw1 ours/uw2 ours/pg ours/hike_07_08_gopro_4 ours/hike_09_26_7 ours/hike_1008_2 ours/hike_09_26_1)
            SKIPS=(0 0 0 2 0 2 0)
            SCENE=${SCENES[$JOB_COMPLETION_INDEX]}
            SKIP=${SKIPS[$JOB_COMPLETION_INDEX]}
            SCENE_NAME=${SCENE}/skip_${SKIP}
            sudo mkdir -p /home/docker/.cache/torch/hub/checkpoints/
            sudo chown docker /home/docker/.cache/torch/hub/checkpoints/ -R
            cp checkpoints/vgg16-397923af.pth /home/docker/.cache/torch/hub/checkpoints/vgg16-397923af.pth
            cp checkpoints/vgg.pth /home/docker/.cache/torch/hub/checkpoints/vgg.pth
            cd comparison/bundle-adjusting-NeRF
            # python train.py --output_root=../../data/logs_eval/barf --group="" --model=barf --yaml=barf_iphone --name=${SCENE_NAME} --data.root=../../data/sequenced --data.scene=${SCENE_NAME} --barf_c2f=[0.1,0.5]
            python evaluate.py --output_root=../../data/logs_eval/barf --group="" --model=barf --yaml=barf_iphone --name=${SCENE_NAME} --data.root=../../data/sequenced --data.scene=${SCENE_NAME} --data.val_sub= --resume
      volumes:
      - name: uberlapse
        persistentVolumeClaim:
          claimName: uberlapse
      priorityClassName: high
